{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6495e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from bpnet_customize.io_ import PeakGenerator\n",
    "from bpnet_customize.io_ import extract_loci\n",
    "import json\n",
    "from bpnet_customize.bpnet import BPNet\n",
    "import nbimporter\n",
    "import cnn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75b28d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_fit_parameters = {\n",
    "    'n_filters': 64,\n",
    "    'n_layers': 8,\n",
    "    'profile_output_bias': True,\n",
    "    'count_output_bias': True,\n",
    "    'name': None,\n",
    "    'batch_size': 64,\n",
    "    'in_window': 2114,\n",
    "    'out_window': 1000,\n",
    "    'max_jitter': 128,\n",
    "    'reverse_complement': True,\n",
    "    'max_epochs': 50,\n",
    "    'validation_iter': 100,\n",
    "    'lr': 0.001,\n",
    "    'alpha': 1,\n",
    "    'verbose': False,\n",
    "\n",
    "    'min_counts': 0,\n",
    "    'max_counts': 99999999,\n",
    "\n",
    "    'training_chroms': ['chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', \n",
    "        'chr9', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', \n",
    "        'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX'],\n",
    "    'validation_chroms': ['chr8', 'chr10'],\n",
    "    'sequences': None,\n",
    "    'loci': None,\n",
    "    'signals': None,\n",
    "    'controls': None,\n",
    "    'random_state': None\n",
    "    }\n",
    "\n",
    "def merge_parameters(parameters, default_parameters):\n",
    "    with open(parameters, \"r\") as infile:\n",
    "        parameters = json.load(infile)\n",
    "\n",
    "    for parameter, value in default_parameters.items():\n",
    "        if parameter not in parameters:\n",
    "            if value is None and parameter != \"controls\":\n",
    "                raise ValueError(\"Must provide value for '{}'\".format(parameter))\n",
    "\n",
    "            parameters[parameter] = value\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdd08775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit parameter\n",
    "\n",
    "fit_para = merge_parameters(\"Data/json/fit.json\", default_fit_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bb09028",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Loci: 100%|███████████████████████| 3749/3749 [00:02<00:00, 1640.39it/s]\n",
      "Loading Loci: 100%|███████████████████████| 5666/5666 [00:02<00:00, 1927.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size:  3749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0.,  ..., 0., 1., 1.],\n",
       "         [0., 1., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 1., 0.],\n",
       "         [1., 0., 0.,  ..., 1., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 1.],\n",
       "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [1., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 1., 1., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 1., 0., 0.],\n",
       "         [1., 0., 1.,  ..., 0., 1., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 1.]],\n",
       "\n",
       "        [[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 1., 1., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 1.]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Size:  5666\n",
      "Epoch\tIteration\tTraining Time\tValidation Time\tTraining MNLL\tTraining Count MSE\tValidation MNLL\tValidation Profile Pearson\tValidation Count Pearson\tValidation Count MSE\tSaved?\n",
      "0\t0\t3.8665\t68.2027\t408.7278\t13.3795\t891.6004\t0.0005122318\t0.13394558\t4.5433\tTrue\n",
      "1\t100\t121.1912\t72.9908\t519.8365\t3.3667\t377.0948\t0.042791344\t0.10566397\t2.0463\tTrue\n",
      "3\t200\t70.0543\t66.8396\t423.8701\t0.5417\t363.0977\t0.115572385\t0.1471116\t1.0467\tTrue\n",
      "5\t300\t16.0024\t66.8227\t433.6124\t0.7197\t330.6847\t0.23323897\t0.21064186\t0.7596\tTrue\n",
      "6\t400\t132.2588\t84.9186\t383.2237\t0.4858\t320.3094\t0.25925264\t0.31981876\t0.8492\tTrue\n",
      "8\t500\t79.6285\t73.0666\t396.0485\t0.4515\t317.5337\t0.26761872\t0.41197154\t0.8388\tTrue\n",
      "10\t600\t26.4561\t62.1292\t413.5856\t0.5612\t314.5002\t0.27353555\t0.46600217\t0.7039\tTrue\n",
      "11\t700\t136.218\t63.7203\t437.7029\t0.4682\t313.4678\t0.27578235\t0.48485813\t0.6687\tTrue\n",
      "13\t800\t87.8322\t71.5903\t358.0885\t0.4695\t312.556\t0.27718776\t0.5130254\t0.7055\tTrue\n",
      "15\t900\t50.3742\t68.9826\t387.1257\t0.4125\t311.4565\t0.2802622\t0.51013833\t0.7515\tTrue\n",
      "16\t1000\t131.7864\t64.1815\t371.1506\t0.5238\t311.054\t0.28205198\t0.51618844\t0.7999\tTrue\n",
      "18\t1100\t75.8244\t63.9616\t335.2215\t0.4271\t310.8299\t0.28277943\t0.52105916\t0.6824\tTrue\n",
      "20\t1200\t50.6475\t64.0989\t346.9372\t0.4457\t310.4582\t0.28287846\t0.515538\t0.6823\tTrue\n",
      "22\t1300\t6.9671\t66.4549\t450.0793\t0.3897\t311.9715\t0.28426915\t0.5273068\t0.9114\tFalse\n",
      "23\t1400\t108.5513\t63.7646\t393.7408\t0.493\t310.3674\t0.2838024\t0.5171381\t0.73\tTrue\n",
      "25\t1500\t61.3737\t64.0668\t365.4146\t0.39\t310.0873\t0.2847472\t0.524155\t0.676\tTrue\n",
      "27\t1600\t18.1079\t64.5742\t372.6631\t0.4263\t309.9192\t0.28591546\t0.52358955\t0.7254\tTrue\n",
      "28\t1700\t118.6648\t438.1313\t384.1964\t0.413\t309.6694\t0.28545693\t0.5283473\t0.6605\tTrue\n",
      "30\t1800\t72.1151\t60.3203\t342.9459\t0.3798\t309.8695\t0.28481492\t0.5283458\t0.7372\tFalse\n",
      "32\t1900\t28.7672\t86.2272\t408.3124\t0.3858\t309.3199\t0.2863361\t0.54099107\t0.6994\tTrue\n",
      "33\t2000\t117.7462\t58.846\t363.102\t0.3868\t309.2816\t0.2862485\t0.53276837\t0.6299\tTrue\n",
      "35\t2100\t94.9276\t65.1915\t382.7822\t0.2997\t310.4928\t0.28626338\t0.5346776\t0.6169\tFalse\n",
      "37\t2200\t39.646\t63.8051\t425.7093\t0.5096\t309.2606\t0.28610253\t0.5288125\t0.6057\tTrue\n",
      "38\t2300\t218.2957\t59.9221\t390.064\t0.6345\t309.3326\t0.28667438\t0.5407115\t0.7887\tFalse\n",
      "40\t2400\t144.524\t92.6581\t409.7692\t0.4211\t309.8421\t0.285516\t0.5453323\t0.7107\tFalse\n",
      "42\t2500\t66.41\t72.0217\t373.841\t0.448\t309.4294\t0.2856067\t0.5372865\t0.7909\tFalse\n",
      "44\t2600\t12.6355\t62.2995\t377.5053\t0.4361\t309.9831\t0.28502792\t0.54122376\t0.7282\tFalse\n",
      "45\t2700\t142.0166\t91.3942\t357.4771\t0.5014\t308.9753\t0.28686127\t0.54420793\t0.6734\tTrue\n",
      "47\t2800\t88.5262\t97.724\t338.7979\t0.3409\t309.6322\t0.28430748\t0.53339005\t0.5991\tFalse\n",
      "49\t2900\t33.933\t86.1482\t388.289\t0.3981\t309.439\t0.28516904\t0.5367358\t0.738\tFalse\n"
     ]
    }
   ],
   "source": [
    "# Fit\n",
    "\n",
    "training_data = PeakGenerator(\n",
    "    loci=fit_para['loci'], \n",
    "    sequences=fit_para['sequences'],\n",
    "    signals=fit_para['signals'],\n",
    "    controls=fit_para['controls'],\n",
    "    chroms=fit_para['training_chroms'],\n",
    "    in_window=fit_para['in_window'],\n",
    "    out_window=fit_para['out_window'],\n",
    "    max_jitter=fit_para['max_jitter'],\n",
    "    reverse_complement=fit_para['reverse_complement'],\n",
    "    min_counts=fit_para['min_counts'],\n",
    "    max_counts=fit_para['max_counts'],\n",
    "    random_state=fit_para['random_state'],\n",
    "    batch_size=fit_para['batch_size'],\n",
    "    verbose=fit_para['verbose']\n",
    ")\n",
    "\n",
    "# training_data = cnn.getInput(\"Data/hg38.fa\")\n",
    "\n",
    "valid_data = extract_loci(\n",
    "    sequences=fit_para['sequences'],\n",
    "    signals=fit_para['signals'],\n",
    "    controls=fit_para['controls'],\n",
    "    loci=fit_para['loci'],\n",
    "    chroms=fit_para['validation_chroms'],\n",
    "    in_window=fit_para['in_window'],\n",
    "    out_window=fit_para['out_window'],\n",
    "    max_jitter=0,\n",
    "    verbose=fit_para['verbose']\n",
    ")\n",
    "\n",
    "if fit_para['controls'] is not None:\n",
    "    valid_sequences, valid_signals, valid_controls = valid_data\n",
    "    n_control_tracks = 2\n",
    "else:\n",
    "    valid_sequences, valid_signals = valid_data\n",
    "    valid_controls = None\n",
    "    n_control_tracks = 0\n",
    "    \n",
    "trimming = (fit_para['in_window'] - fit_para['out_window']) // 2\n",
    "\n",
    "model = BPNet(n_filters=fit_para['n_filters'], \n",
    "    n_layers=fit_para['n_layers'],\n",
    "    n_outputs=len(fit_para['signals']),\n",
    "    n_control_tracks=n_control_tracks,\n",
    "    profile_output_bias=fit_para['profile_output_bias'],\n",
    "    count_output_bias=fit_para['count_output_bias'],\n",
    "    alpha=fit_para['alpha'],\n",
    "    trimming=trimming,\n",
    "    name=fit_para['name'],\n",
    "    verbose=fit_para['verbose'])#.cuda()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=fit_para['lr'])\n",
    "\n",
    "if fit_para['verbose']:\n",
    "    print(\"Training Set Size: \", training_data.dataset.sequences.shape[0])\n",
    "    display(training_data.dataset.sequences)\n",
    "    print(\"Validation Set Size: \", valid_sequences.shape[0])\n",
    "\n",
    "model.fit(training_data, optimizer, X_valid=valid_sequences, \n",
    "    X_ctl_valid=valid_controls, y_valid=valid_signals, \n",
    "    max_epochs=fit_para['max_epochs'], \n",
    "    validation_iter=fit_para['validation_iter'], \n",
    "    batch_size=fit_para['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eb56a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict parameters\n",
    "\n",
    "default_predict_parameters = {\n",
    "    'batch_size': 64,\n",
    "    'in_window': 2114,\n",
    "    'out_window': 1000,\n",
    "    'verbose': False,\n",
    "    'chroms': ['chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', \n",
    "        'chr9', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', \n",
    "        'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX'],\n",
    "    'sequences': None,\n",
    "    'loci': None,\n",
    "    'controls': None,\n",
    "    'model': None,\n",
    "    'profile_filename': 'y_profile.npz',\n",
    "    'counts_filename': 'y_counts.npz'\n",
    "}\n",
    "\n",
    "predict_para = merge_parameters(\"Data/json/predict.json\", default_predict_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2fab0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Loci: 100%|███████████████████████| 5666/5666 [00:02<00:00, 2665.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "\n",
    "model = torch.load(predict_para['model'])#.cuda()\n",
    "\n",
    "examples = extract_loci(\n",
    "    sequences=predict_para['sequences'],\n",
    "    controls=predict_para['controls'],\n",
    "    loci=predict_para['loci'],\n",
    "    chroms=predict_para['chroms'],\n",
    "    max_jitter=0,\n",
    "    verbose=predict_para['verbose']\n",
    ")\n",
    "\n",
    "if predict_para['controls'] == None:\n",
    "    X = examples\n",
    "    if model.n_control_tracks > 0:\n",
    "        X_ctl = torch.zeros(X.shape[0], model.n_control_tracks, X.shape[-1])\n",
    "    else:\n",
    "        X_ctl = None\n",
    "else:\n",
    "    X, X_ctl = examples\n",
    "\n",
    "y_profiles, y_counts = model.predict(X, X_ctl=X_ctl, \n",
    "    batch_size=predict_para['batch_size'])\n",
    "\n",
    "np.savez_compressed(predict_para['profile_filename'], y_profiles)\n",
    "np.savez_compressed(predict_para['counts_filename'], y_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70c47e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<numpy.lib.npyio.NpzFile at 0x1051eaa90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(predict_para['profile_filename'])\n",
    "np.load(predict_para['counts_filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64bfa5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
